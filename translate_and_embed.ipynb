{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "import json\n",
    "import numpy as np\n",
    "import openai\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the docx file\n",
    "text = docx2txt.process('story.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data\n",
    "min_len = 50\n",
    "filter_story = [line for line in text.split('\\n') if len(line) > min_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lan(comment, lan=\"en\"):\n",
    "    # Using the api call to translate the comment to any language in the azure translator\n",
    "    subscription_key = \"\"\n",
    "    subscription_region = \"\"\n",
    "    domain = \"\"\n",
    "    # Set the headers for the request\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "        \"Ocp-Apim-Subscription-Region\": subscription_region,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    url = f\"https://{domain}.cognitiveservices.azure.com/translator/text/v3.0/translate?to={lan}\"\n",
    "\n",
    "    # Set the JSON data to send in the request body\n",
    "    data = json.dumps([{\"Text\": comment}])\n",
    "\n",
    "    # Send the POST request\n",
    "    response_tanslate = requests.post(url, headers=headers, data=data)\n",
    "    return json.loads(response_tanslate.text)[0][\"translations\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionary and translate the text\n",
    "data_story = {i:{'text_he':line, 'text_en':get_lan(line, lan='en')} for i, line in enumerate(filter_story)}\n",
    "\n",
    "# write a json file\n",
    "with open('data_story.json', 'w') as outfile:\n",
    "    json.dump(data_story, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json data tree.json\n",
    "with open('tree.json') as json_file:\n",
    "    data_story = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctrate a dictionary with embeded numpy array of the text\n",
    "dic_np = {key:openai.Embedding.create(input=data_story[key]['text_en'],      \n",
    " \t\t\t\t\t\t engine=\"text-embedding-ada-002\"\n",
    "                                \t)[\"data\"][0][\"embedding\"]\n",
    "          for key in data_story}\n",
    "\n",
    "# write the dictonery with numpy array to a .npz file\n",
    "np.savez_compressed('dic_np.npz', **dic_np)\n",
    "\n",
    "# read the .npz file\n",
    "loaded_dict = np.load('dic_np.npz', allow_pickle=True)\n",
    "\n",
    "# creating the matrix embedding\n",
    "matrix_embedding = np.array([loaded_dict[key] for key in loaded_dict])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter text here\n",
    "enter_txt_he = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrix embedding\n",
    "matrix_embedding = np.array([loaded_dict[key] for key in loaded_dict])\n",
    "# get the question in english\n",
    "enter_txt_en = get_lan(enter_txt_he, lan=\"en\")\n",
    "\n",
    "# get the question embedding\n",
    "embedding = openai.Embedding.create(input=enter_txt_en, engine=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# calculate the cosine similarity\n",
    "cosine_vector = np.dot(matrix_embedding, embedding) / (\n",
    "    np.linalg.norm(matrix_embedding) * np.linalg.norm(embedding))\n",
    "\n",
    "# get the index of the most similar quote\n",
    "idx_answer = np.argmax(cosine_vector)\n",
    "\n",
    "# get the answer in the original language (hebrew)\n",
    "answer = data_story[idx_answer][\"text_he\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "green",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
